{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our group attempted to create a model that would take in a football players statistics for one season and would output a projected fantasy score for the following year. We wanted to create a model that could be trained on several years worth of data and would choose the model that was best for that dataset. We wanted split up each major fantasy football position into its own model in case there was one model that was better for one position vs. another. We wound up scraping our data online so it will be easy in the future to add in years and incorporate them into our training data. We ultimately were successful in creating this setup and obtaining results that seem relatively accurate to us. We would like to compare our results vs. other prediction algorithms out there for predicting fantasy football performance at some point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/johnny-kantaros/fantasy-football\">Click to see source code!</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project focused on developing a machine learning pipeline for fantasy football applications. All three of us have played fantasy football for a number of years, so we were motivated to see if modeling historic data could lead to accurate predictions for future seasons. For those who are unfamiliar, or need a refresher on what fantasy football is, here is a quick recap:  \n",
    "\n",
    "<b><u>Fantasy Football</u></b>  \n",
    "\n",
    "The primary goal of fantasy football is to select a fantasy team comprised of current NFL players. The standard roster includes one quarter back, two running backs, two wide receivers, one tight end, one kicker, one defensive/special teams unit, and one \"flex,\" which can be an additional running back, wide receiver, or tight end. There is also space for ~5-7 bench players whose points will not count if they remain on the bench. Here is an example roster: \n",
    "\n",
    "<img src = \"./images/roster.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, a fantasy football league will consist of 8-12 teams, and participants will battle head to head against there friends to see whose collective team performs better that week. The league will have playoffs towards the end of the season and eventually a championship.   \n",
    "\n",
    "As you will see in the \"Week 1\" columns on the right, there is one feature named \"Proj,\" which stands for projections. These metrics are very popular and commonly utilized in fantasy football, and team managers will often use them to compare different players and set their lineup each week. Like many, we have always been curious how these projections are generated. There have been several individuals and groups who have also tried to accomplish this task. For example, Chelsea Robinson at Louisiana tech wrote a case study in 2020 with her findings from advanced statistical modeling using historical fantasy data. Similar to us, she relied on regression modeling to output a ranking list for the following season. Although mathematically strong, her model uses less data and fewer features than ours, which might not produce as accurate as a result. Another interesting case study comes Roman Lutz at UMASS Amherst, who employed a similar solution as us. More specifically, he pulled data from over 5 seasons and used SVM regression along with neural networks for optimization. Similar to the first case study, his data was also fairly basic and lacked the advanced features found in ours. Consequently, his MSE was around 6, while ours was closer to 2. This is a significant error difference when it comes to prediction, so we are proud with our result. The last case study worth mentioning comes from Benjamin Hendricks at Harvard. In his approach, Hendricks uses an <i>ensemble</i> method to reach predictions. In his calculations, he leverages data from existing models, applies natural language processing techniques to perform sentiment analysis on player performance, and combines these metrics with standard data from NFL.com and FantasyData.io. Hendricks's use of sentiment analysis and crowd sourcing is a unique approach and feature to include. He relies on the crowd's opinion on players and teams instead of just the \"masters.\" He also includes advanced, real time statistics such as injuries and weather analysis. This is an impressive, detailed approach with great performance (30% better than most sport sites)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values Statement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<u>Potential Users</u>  \n",
    "\n",
    "The potential users of our project are fantasy football team owners. Our data, modeling, and output are all fairly specific, so there will not be many applications outside this domain. It is worth noting that our current output is specific to fantasy football <i>drafts</i>, which take place at the beginning of the year and allow users to pick their team for the year. If we had more time, we would have liked to model for weekly predictions.  \n",
    "\n",
    "<u>Who benefits?</u>  \n",
    "\n",
    "Hopefully, the owners of fantasy football teams who leverage our product will gain increased insight and an edge over their opponents. These users can run our model for that given year and shape their draft off the results.\n",
    "\n",
    "<u>Who is harmed?</u>  \n",
    "\n",
    "While no one will be truly harmed, this algorithm could provide an unfair advantage for certain members of a league. The algorithm should not be used if any sort of wagering is involved in the league, as this could cause for unfair and biased outcomes.  \n",
    "\n",
    "<u>What is your personal reason for working on this problem?</u>  \n",
    "\n",
    "As aforementioned, we all have played fantasy football for a number of years and have been interested with how the projections are produced by major sites like ESPN and Yahoo. We wanted to see if we could replicate and expand on these predictions using the machine learning techniques we have explored this semester.  \n",
    "\n",
    "<u>Societal Impact</u>  \n",
    "\n",
    "There will be very little societal impact of our product. As we mentioned, it is a very specific application of machine learning, and it will primarily be used for fun instead of addressing any societal problems.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materials and Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Our data</u>\n",
    "\n",
    "##### <u>Normal data</u>\n",
    "We wound up scraping most of our data online from various websites that provide NFL player statistics. We tested various websites but the one with the most data that was easily available to scrape was from a website called <a href=\"https://www.fantasypros.com/nfl/stats/\">FantasyPros</a>. This website has cleanly formatted NFL data for every player from each year. They also conveniently split up the players into positional groups, which made our job easier. Furthermore, the url for each position and year was structred in such a way that we could write the following function to web-scrape our basic data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def read_new(year, pos):\n",
    "\n",
    "        # Link takes lowercase positions\n",
    "        pos = pos.lower()\n",
    "\n",
    "        url = f\"https://www.fantasypros.com/nfl/stats/{pos}.php?year={year}\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        html = response.content\n",
    "\n",
    "        # Make df\n",
    "        df = pd.read_html(html, header=1)[0]\n",
    "\n",
    "        # Clean name and team data\n",
    "\n",
    "        df.insert(1, 'Tm', df['Player'].str.rsplit(n=1).str[-1].str.slice(1, -1))\n",
    "        df['Player'] = df['Player'].str.rsplit(n=1).str[0]\n",
    "\n",
    "        # Get y (following year ppg)\n",
    "        next_year = str(int(year) + 1)\n",
    "        url = f\"https://www.fantasypros.com/nfl/stats/{pos}.php?year={next_year}\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        html = response.content\n",
    "\n",
    "        # Make df\n",
    "        y = pd.read_html(html, header=1)[0]\n",
    "\n",
    "        df['y'] = y['FPTS/G']\n",
    "\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what an example basic dataset looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Player</th>\n",
       "      <th>CMP</th>\n",
       "      <th>ATT</th>\n",
       "      <th>PCT</th>\n",
       "      <th>YDS</th>\n",
       "      <th>Y/A</th>\n",
       "      <th>TD</th>\n",
       "      <th>INT</th>\n",
       "      <th>SACKS</th>\n",
       "      <th>ATT.1</th>\n",
       "      <th>YDS.1</th>\n",
       "      <th>TD.1</th>\n",
       "      <th>FL</th>\n",
       "      <th>G</th>\n",
       "      <th>FPTS</th>\n",
       "      <th>FPTS/G</th>\n",
       "      <th>ROST</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BUF</td>\n",
       "      <td>Josh Allen</td>\n",
       "      <td>409</td>\n",
       "      <td>646</td>\n",
       "      <td>63.3</td>\n",
       "      <td>4407</td>\n",
       "      <td>6.8</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>122</td>\n",
       "      <td>763</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>417.7</td>\n",
       "      <td>24.6</td>\n",
       "      <td>99.9%</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LAC</td>\n",
       "      <td>Justin Herbert</td>\n",
       "      <td>443</td>\n",
       "      <td>672</td>\n",
       "      <td>65.9</td>\n",
       "      <td>5014</td>\n",
       "      <td>7.5</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>63</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>395.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>96.6%</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>FA</td>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>485</td>\n",
       "      <td>719</td>\n",
       "      <td>67.5</td>\n",
       "      <td>5316</td>\n",
       "      <td>7.4</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>386.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1.8%</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank   Tm          Player  CMP  ATT   PCT   YDS  Y/A  TD  INT  SACKS  \\\n",
       "0     1  BUF      Josh Allen  409  646  63.3  4407  6.8  36   15     26   \n",
       "1     2  LAC  Justin Herbert  443  672  65.9  5014  7.5  38   15     31   \n",
       "2     3   FA       Tom Brady  485  719  67.5  5316  7.4  43   12     22   \n",
       "\n",
       "   ATT.1  YDS.1  TD.1  FL   G   FPTS  FPTS/G   ROST     y  \n",
       "0    122    763     6   3  17  417.7    24.6  99.9%  25.2  \n",
       "1     63    302     3   1  17  395.6    23.3  96.6%  24.3  \n",
       "2     28     81     2   3  17  386.7    22.7   1.8%  25.6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_new(2021, \"QB\")\n",
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each row represents a singular NFL player. In this case, we pulled QB data from 2021, so each row will represent a quarterback and their respective stats from that season.  There are many features which display player performance throughout the season. Some example stats include ATT (pass attempts), YDS (passing yards), TD (touchdowns), CMP (completions). Our target variable, which we are trying to predict in future years, is FPTS/G: This is what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     24.6\n",
       "1     23.3\n",
       "2     22.7\n",
       "3     22.0\n",
       "4     20.4\n",
       "      ... \n",
       "78    -0.3\n",
       "79    -0.1\n",
       "80    -0.2\n",
       "81    -0.5\n",
       "82    -0.4\n",
       "Name: FPTS/G, Length: 83, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FPTS/G']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided on fantasy points per game instead of total fantasy points to account for injuries and other potential limitations of an aggregate value. For example, in our first modeling approach, when we used total fantasy points, some of the top players received extremely low predictions for the following season. One example was Saquon Barkley, who is a top running back in the league. One year, he only played in 2 games due to a season ending injury. However, in those two games, he averaged ~15 points per game. In this regard, although he recorded one of the lowest total points for that year, he was one of the best players.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <u>Advanced Data</u>\n",
    "\n",
    "We also pulled <a href=\"https://www.fantasypros.com/nfl/advanced-stats-qb.php?year=2021\">advanced player data</a> from the same website, which brings in some more advanced calculations into our dataset. While many of these metrics are important, they are often skipped by the mainstream media due to their complicated nature or low appeal for their audience. Because the two datasets came from the same website, we could use a similar approach for our web-scraping, and the merge was made easier due to matching names. One area which required a little massaging was ensuring we did not have duplicate variables. As you will see in our basic data, there are multiple Td, Yds, Att columns. This represents passing vs rushing statistics. As each position had slightly different data, it became important to us to invest time in cleaning / un-duplicating these features. Additionally, many columns were repeated in the merging process with the advanced dataset. To clean this data in an efficient and organized way, we wrote a bunch of functions in our main class file to help us tackle the problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wound up training our model on every year except for the most recent. This allowed us to test our results against the most recent years worth of data. We evaluated our models based on MSE. If a model provided a better MSE than the model we had previously saved as the best, we would update and now return the new type of model. Our biggest hurdle was aquiring enough data to run an effective model as there are only 32 teams and some positions only have 1 that gets points. We had to take several years worth to help us overcome this challenge."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Our approach</u>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Data collection\n",
    "\n",
    "A big problem we faced was a lack of data. More specifically, we initially started with just one season of data to make our predictions. This quickly caused problems, as in some positional groups we were left with only ~30 players as observations after cleaning and preparing our data. Therefore, we switched our data source and layered ~10 seasons worth of data onto each positional group. We ended up removing player names as a feature, as this could have ended up being a feature due to repeated values over different years. This left us with hundreds of observations to work with.\n",
    "\n",
    "\n",
    "##### Preprocessing\n",
    "\n",
    "Before we employed our models, we performed feature selection and normalization techniques. First, because of our merged dataset, we had a copious amount of features to choose from. We relied on sklearn's SelectKBest algorithm for most of the heavy lifting. Before this process, however, we made sure to standardize our data to ensure the feature selection algorithm did not favor features with naturally larger values. Here is our feature selection function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "def getBestFeatures(X, y, numFeatures = 5):\n",
    "        \n",
    "        # Get best features\n",
    "        selector = SelectKBest(score_func=f_regression, k=numFeatures)\n",
    "        selector.fit(X, y)\n",
    "\n",
    "        selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "        X_selected = X[selected_features]\n",
    "\n",
    "        return X_selected, selected_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each positional group, the 5 selected features were different and unique to that position. For example, 20+ yard receptions are much more important in predicting wide receiver performance than they are for quarterbacks, who pass the ball.  \n",
    "\n",
    "##### Modeling\n",
    "\n",
    "* TODO - talk about modeling function, what it returns, which models we used\n",
    "\n",
    "Next, we performed our modeling.\n",
    "\n",
    "\n",
    "##### Performance evaluation\n",
    "\n",
    "* TODO - talk about metrics\n",
    "\n",
    "How you evaluated your models (loss, accuracy, etc), and the size of your test set.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TODO\n",
    "\n",
    "\n",
    "This is the section in which you describe the main findings or achievements of your model. You can report things like accuracies on train/test data, loss scores, comparisons to previous models, etc. To compare a small set of numbers, tables are fine, but more complex phenomena should be illustrated with figures. Both figures and tables should include appropriate captions, axis labels, legends, and another professional annotations. Itâ€™s fine for your figures to either be constructed manually or as computational outputs (e.g. from Pandas).\n",
    "\n",
    "Please remember: your results do not speak for themselves. While figures and tables are highly effective forms of communication, your prose is necessary to tell your story."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluding Discussion\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* TODO\n",
    "\n",
    "Your conclusion is the right time to assess:\n",
    "\n",
    "In what ways did our project work?\n",
    "\n",
    "Did we meet the goals that we set at the beginning of the project?\n",
    "\n",
    "How do our results compare to the results of others who have also studied similar problems?\n",
    "\n",
    "If we had more time, data, or computational resources, what might we do differently in order to improve further?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Contributions Statement\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your group contributions statement, please include a short paragraph for each group member describing how they contributed to the project:\n",
    "\n",
    "\n",
    "Who worked on which parts of the source code?\n",
    "\n",
    "Who performed or visualized which experiments?\n",
    "\n",
    "Who led the writing of which parts of the blog post?\n",
    "\n",
    "Etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Ethan Coomber</u>:   \n",
    "\n",
    "I spent a lot of time working on cleaning data and developing the model. We had to make sure we had sufficient data and I tried to ensure we had clean, usable data. Once I was able to ensure that, I spent my time working on developing a way to choose the best model. This took time as we had to research various models and determine what kind of model would be most effective in helping us predict performance. We then implemented the models we thought had potential and had to have a way to select the best one.\n",
    "\n",
    "\n",
    "<u>Johnny Kantaros</u>:  \n",
    "\n",
    "I spent time initially working on data collection (including the web-scraping), and then spent a lot of time on data cleaning and preprocessing tactics. A large portion of this project was data collection, manipulation, and wrangling, and I definitely learned a lot about the various functionalities of Pandas and other frameworks. Finally, I helped Ethan with adding some models to our modeling function. Our team did a great job working collaboratively so everyone achieved learning in all parts of the pipeline. In terms of this blog post, I wrote the introduction, values statements, and part of the materials + methods sections."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal Reflection\n",
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the very end of your blog post, in a few paragraphs, respond to the following questions:\n",
    "\n",
    "What did you learn from the process of researching, implementing, and communicating about your project?\n",
    "\n",
    "How do you feel about what you achieved? Did meet your initial goals? Did you exceed them or fall short? In what ways?\n",
    "\n",
    "In what ways will you carry the experience of working on this project into your next courses, career stages, or personal life?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources below * delete when bib is working"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robinson, Chelsea. \"The Prediction of Fantasy Football.\" Louisiana Tech University, 14 May 2020,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lutz, Roman. \"Fantasy Football Prediction.\" University of Massachusetts, Amherst, 26 May 2015."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hendricks, Benjamin. Sports Analytics with Natural Language Processing: Using Crowd Sentiment to Help Pick Winners in Fantasy Football, Harvard University, Massachusetts, 2022."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
